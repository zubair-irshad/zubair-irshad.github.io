<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description"
        content="Zubair Irshad. Research Scientist at Toyota Research Institute | Georgia Tech PhD | Fulbright Scholar. My research interests lie in Artificial Intelligence, Computer Vision and Deep Learning.">
    <title>Zubair Irshad</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&family=Roboto:wght@300;400;500;700&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="icon" href="images/profile.jpg" type="image/png">
</head>

<body>
    <!-- Blue Vignette Effect -->
    <div class="vignette"></div>

    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-brand">
            <a href="#"><span>Zubair</span> Irshad</a>
        </div>
        <ul class="nav-links">
            <li><a href="#about" class="active">About</a></li>
            <li><a href="publications.html">Publications</a></li>
            <li><a href="https://zubairirshad.com/irshad_zubair_resume/" target="_blank">Resume</a></li>
        </ul>
    </nav>

    <!-- Hero Section with About Me -->
    <section class="hero" id="about">
        <div class="container">
            <div class="hero-content">
                <div class="hero-left">
                    <div class="profile-image">
                        <img src="images/profile.jpg" alt="Zubair Irshad">
                    </div>
                    <p class="hero-name"><span>ZUBAIR</span> IRSHAD</p>
                    <p class="hero-title">Research Scientist</p>
                    <div class="social-icon-links">
                        <div class="social-icons">
                            <a href="#" title="Location"><i class="fas fa-map-marker-alt"></i></a>
                            <a href="mailto:muhammadzubairirshad@gmail.com" title="Email"><i
                                    class="fas fa-envelope"></i></a>
                            <a href="https://www.linkedin.com/in/zubair-irshad/" target="_blank" title="LinkedIn"><i
                                    class="fab fa-linkedin"></i></a>
                            <a href="https://twitter.com/mzubairirshad" target="_blank" title="Twitter"><i
                                    class="fab fa-x-twitter"></i></a>
                            <a href="https://github.com/zubair-irshad" target="_blank" title="GitHub"><i
                                    class="fab fa-github"></i></a>
                            <a href="https://scholar.google.com/citations?user=K2XA5XEAAAAJ&hl=en" target="_blank"
                                title="Google Scholar"><i class="fas fa-graduation-cap"></i></a>
                            <a href="https://www.youtube.com/channel/UC9BY9TjDiI0Qfv_kvraQ7fA" target="_blank"
                                title="YouTube"><i class="fab fa-youtube"></i></a>
                        </div>
                        <div class="social-labels">
                            <a href="#">Silicon Valley, CA, USA</a>
                            <a href="mailto:muhammadzubairirshad@gmail.com">Email</a>
                            <a href="https://www.linkedin.com/in/zubair-irshad/" target="_blank">Linkedin</a>
                            <a href="https://twitter.com/mzubairirshad" target="_blank">Twitter</a>
                            <a href="https://github.com/zubair-irshad" target="_blank">Github</a>
                            <a href="https://scholar.google.com/citations?user=K2XA5XEAAAAJ&hl=en"
                                target="_blank">Google Scholar</a>
                            <a href="https://www.youtube.com/channel/UC9BY9TjDiI0Qfv_kvraQ7fA"
                                target="_blank">Youtube</a>
                        </div>
                    </div>
                </div>
                <div class="hero-right">
                    <h2>ABOUT ME!</h2>
                    <div class="about-content">
                        <p>I am a Machine Learning Research Scientist at <a
                                href="https://toyotaresearchinstitute.github.io/lbm1/">Toyota Research Institute</a>
                            working on
                            <a href="https://www.tri.global/">Large Behavior Models</a> and Deep-learning based 3D
                            perception
                            systems for Robotics. More recently, I have been a core contributor to the <a
                                href="https://arxiv.org/abs/2507.05331">LBM 1.0</a> multi-task policy learning and
                            post-training
                            efforts. I received my PhD in the <a
                                href="https://www.me.gatech.edu/phd-degree-program">George W.
                                Woodruff School of Mechanical Engineering</a> at <a href="http://gatech.edu">Georgia
                                Institute
                                of Technology</a>. I was advised by <a href="https://faculty.cc.gatech.edu/~zk15/">Dr.
                                Zsolt
                                Kira</a> from the Robotics, Perception and Learning (RIPL) Lab. My PhD thesis is titled
                            Learning
                            3D Robotics Perception using Inductive Priors. My thesis is available <a
                                href="https://repository.gatech.edu/entities/publication/01ef518d-5235-4131-990c-f552d3b309c6">here</a>
                            and the dissertation defense video <a
                                href="https://youtu.be/3M2ze1gZjj8?si=uD14_bXQUl9pwDQi">here</a>. My current research
                            covers the
                            following topics:
                        </p>

                        <ul class="research-topics">
                            <li><strong>3D Perception:</strong> 3D Reconstruction, NeRF, Gaussian Splatting,
                                Representation
                                Learning, 6D pose estimation</li>
                            <li><strong>Generative AI:</strong> Diffusion Models, Generative Action Models, Data
                                Augmentation
                                and Data Generation for Robotics</li>
                            <li><strong>Multimodal AI:</strong> Vision-and-Language, Embodied AI, Semantic
                                Understanding,
                                Spatio-temporal learning</li>
                        </ul>

                        <p>I'm also a technical reviewer for Machine Learning and Robotics Conferences including CVPR,
                            ECCV,
                            ICCV, ICLR, Neurips, ICRA, IROS, RSS, RA-L and the lead co-organizer of RoboNeRF Workshop at
                            ICRA'24
                            and Robo 3D-VLM workshop at CVPR'25! Below you will find my projects portfolio. You can find
                            my
                            updated resume <a href="https://zubairirshad.com/irshad_zubair_resume/">here</a>.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Affiliations Section -->
    <section class="affiliations-section">
        <div class="container">
            <h2>Affiliations</h2>
            <div class="affiliations-grid">
                <div class="affiliation-item">
                    <img src="images/logos/tri_logo.png" alt="TRI" class="affiliation-logo">
                    <span class="affiliation-name">TRI</span>
                    <span class="affiliation-years">2021 – Present</span>
                </div>
                <div class="affiliation-item">
                    <img src="images/logos/gatech_logo.png" alt="Georgia Tech" class="affiliation-logo">
                    <span class="affiliation-name">Georgia Tech</span>
                    <span class="affiliation-years">2017 – 2023</span>
                </div>
                <div class="affiliation-item">
                    <img src="images/logos/fulbright_logo.png" alt="Fulbright" class="affiliation-logo">
                    <span class="affiliation-name">Fulbright</span>
                    <span class="affiliation-years">2017 – 2019</span>
                </div>
                <div class="affiliation-item">
                    <img src="images/logos/sri_logo.svg
                     " alt="SRI International" class="affiliation-logo">
                    <span class="affiliation-name">SRI International</span>
                    <span class="affiliation-years">Summer 2020</span>
                </div>
                <div class="affiliation-item">
                    <img src="images/logos/giki_logo.png" alt="GIKI" class="affiliation-logo">
                    <span class="affiliation-name">GIKI</span>
                    <span class="affiliation-years">2011-2015</span>
                </div>
            </div>
        </div>
    </section>

    <!-- News Section -->
    <section class="news-section">
        <div class="container">
            <h2>NEWS</h2>
            <div class="news-list" id="news-list">
                <div class="news-item"><span class="news-date">[Nov 2025]</span><span class="news-text"><a
                            href="https://arxiv.org/abs/2505.04612">FastMap</a> accepted to <a
                            href="https://3dvconf.github.io/2026/">3DV'26!</a></span></div>
                <div class="news-item"><span class="news-date">[Oct 2025]</span><span class="news-text">Invited talk at
                        <a href="https://wclop.github.io/">ICCV'25 Workshop</a>. Talk title: <a
                            href="https://drive.google.com/file/d/1KCTZY0qeRS3bsAzD1Mz7Pb4EjKxUAndW/view?usp=sharing">Pose
                            Estimation in Robotics: From Object Understanding to Camera Calibration</a></span></div>
                <div class="news-item"><span class="news-date">[Oct 2025]</span><span class="news-text">Started as an
                        Associate Editor for
                        Robot Learning at <a href="https://www.corl.org/">ICRA'26</a>!</span></div>
                <div class="news-item"><span class="news-date">[Sep 2025]</span><span class="news-text">Attending the <a
                            href="https://www.corl.org/">Conference on Robot Learning</a> in Seoul, Korea to help
                        present <a href="https://real2render2real.com/">Real2Render2Real</a></span></div>
                <div class="news-item"><span class="news-date">[Aug 2025]</span><span class="news-text"><a
                            href="https://bostondynamics.com/blog/large-behavior-models-atlas-find-new-footing/">Blog
                            Post</a> released integrating our first <a
                            href="https://toyotaresearchinstitute.github.io/lbm1/">TRI LBM</a> with Boston Dynamics'
                        Atlas!</span>
                </div>
                <div class="news-item"><span class="news-date">[Jul 2025]</span><span class="news-text"><a
                            href="https://arxiv.org/abs/2507.05331">Large Behavior Models</a> is up on arXiv—I'm a core
                        contributor to multi-task policy learning and post-training efforts.</span></div>
                <div class="news-item"><span class="news-date">[Jul 2025]</span><span class="news-text">Invited talk at
                        <a href="https://giki.edu.pk/">GIKI</a> on Embodied Artificial Intelligence for 3D Perception
                        leveraging Inductive Priors.</span></div>
                <div class="news-item"><span class="news-date">[Jun 2025]</span><span class="news-text">Two <a
                            href="https://iccv.thecvf.com/">ICCV'25</a> papers on 3D Gaussian Splatting for object-goal
                        navigation and 3D articulated object reconstruction.</span></div>
                <div class="news-item"><span class="news-date">[Apr 2025]</span><span class="news-text">Released <a
                            href="https://x.com/mzubairirshad/status/1915188232100434068">Posed-DROID</a>, improved
                        camera
                        calibration for the DROID dataset.</span></div>
                <div class="news-item"><span class="news-date">[Feb 2025]</span><span class="news-text">Two <a
                            href="https://cvpr.thecvf.com/">CVPR 2025</a> papers accepted on <a
                            href="https://mvgd.github.io/">Zero-shot novel-view and depth synthesis</a> and <a
                            href="https://sh8.io/#/zerograsp">Zero-shot robotics grasping</a>!</span></div>
                <div class="news-item"><span class="news-date">[Jan 2025]</span><span class="news-text">Our paper on
                        object-centric
                        Gaussian Splats for 3D tracking i.e. <a
                            href="https://berkeleyautomation.github.io/POGS/">POGS</a>
                        has been accepted to <a href="https://2025.ieee-icra.org/">ICRA'25!</a></span></div>
                <div class="news-item"><span class="news-date">[Dec 2024]</span><span class="news-text">CVPR Workshop
                        accepted on <a href="https://robo-3dvlms.github.io/">3D Vision Language Models (VLMs) for
                            Robotics</a>. Call
                        for papers coming soon!</span></div>
                <div class="news-item"><span class="news-date">[Oct 2024]</span><span class="news-text">Our
                        comprehensive survey on <a href="https://robonerf.github.io/">Neural Fields in Robotics</a>, is
                        now available on <a href="https://arxiv.org/pdf/2410.20220">arXiv</a>!</span></div>
                <div class="news-item"><span class="news-date">[Sep 2024]</span><span class="news-text"><a
                            href="https://rovi-aug.github.io/">RoVi-Aug</a>, diffusion-based data-augmentation for
                        robotics
                        manipulation, accepted to <a href="https://www.corl.org/">CORL'24</a>!</span></div>
                <div class="news-item"><span class="news-date">[Jul 2024]</span><span class="news-text"><a
                            href="https://nerf-mae.github.io/">NeRF-MAE</a>, large-scale pretraining using NeRFs,
                        accepted
                        to <a href="https://eccv.ecva.net/">ECCV'24</a>!</span></div>
                <div class="news-item hidden"><span class="news-date">[Dec 2024]</span><span class="news-text">Invited
                        talk at <a href="https://woven.toyota/en/">Woven by Toyota (Robotics)</a> on Learning 3D
                        Robotics
                        Perception using Inductive Priors!</span></div>
                <div class="news-item hidden"><span class="news-date">[Oct 2024]</span><span class="news-text">Our
                        paper, <a href="https://rovi-aug.github.io/">RoVi-Aug</a>, has been covered by the press at <a
                            href="https://techxplore.com/news/2024-10-augmentation-algorithm-skills-robots.html">TechXplore</a>!</span>
                </div>
                <div class="news-item hidden"><span class="news-date">[Aug 2024]</span><span class="news-text">Gave an
                        invited talk at Habib
                        University on <a href="https://zubairirshad.com/towards_embodied_3d_foundation_models/">Towards
                            Embodied 3D Foundation Models</a>.</span></div>
                <div class="news-item hidden"><span class="news-date">[Jun 2024]</span><span class="news-text">Three <a
                            href="https://iros2024-abudhabi.org/">IROS'24</a> papers on <a
                            href="https://woven-planet.github.io/DiffusionNOCS/">Diffusion-based 6D Pose Estimation</a>,
                        <a href="https://berkeleyautomation.github.io/LEGS/">Language-embedded Gaussian Splat</a> and <a
                            href="https://berkeleyautomation.github.io/MANIP/">Interactive Perception</a>!</span></div>
                <div class="news-item hidden"><span class="news-date">[Jun 2024]</span><span class="news-text">Attending
                        <a href="https://cvpr.thecvf.com/">CVPR'24</a> remotely. We will present two workshop posters,
                        <a href="https://nerf-mae.github.io/">NeRF-MAE</a> and <a
                            href="https://ice-gaussian.github.io/">ICE-Gaussian</a>!</span></div>
                <div class="news-item hidden"><span class="news-date">[May 2024]</span><span class="news-text">Our paper
                        <a href="https://droid-dataset.github.io/">DROID</a>, a large scale dataset for robotics policy
                        learning, accepted to <a href="https://roboticsconference.org/2024/">RSS 2024!</a></span></div>
                <div class="news-item hidden"><span class="news-date">[May 2024]</span><span class="news-text">Our paper
                        <a href="https://robotics-transformer-x.github.io/">Open X-Embodiment</a>, a large-scale
                        robotics
                        learning dataset collaboration, got best paper awards at <a
                            href="https://2024.ieee-icra.org/">ICRA
                            2024!</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Apr 2024]</span><span class="news-text"><a
                            href="https://fsd6d.github.io/">FSD</a> on fast self-supervised 6D pose estimation accepted
                        to <a href="https://2024.ieee-icra.org/">ICRA'24</a>!</span></div>
                <div class="news-item hidden"><span class="news-date">[Mar 2024]</span><span class="news-text">Two
                        workshop papers on <a href="https://nerf-mae.github.io/">NeRF-MAE</a> and <a
                            href="https://ice-gaussian.github.io/">ICE-Gaussian</a> accepted to <a
                            href="https://cvpr.thecvf.com/">CVPR'24</a> Workshops!</span></div>
                <div class="news-item hidden"><span class="news-date">[Jan 2024]</span><span class="news-text">Our
                        paper, <a href="https://zubair-irshad.github.io/projects/CenterSnap.html">CenterSnap</a>,
                        accepted into <a
                            href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=7083369">RA-L</a>!</span>
                </div>
                <div class="news-item hidden"><span class="news-date">[Dec 2023]</span><span class="news-text">Passed my
                        PhD defense and received my doctorate! My thesis is titled <a
                            href="https://repository.gatech.edu/entities/publication/01ef518d-5235-4131-990c-f552d3b309c6">"Learning
                            3D Robotics Perception using Inductive Priors"</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Dec 2023]</span><span class="news-text">Started
                        full-time as a Research Scientist at <a href="https://www.tri.global/">Toyota Research
                            Institute</a> in the Robotics Perception team!</span></div>
                <div class="news-item hidden"><span class="news-date">[Aug 2023]</span><span class="news-text">Accepted
                        to <a href="https://iccv2023.thecvf.com/call.for.participation-363200-2-30-32.php">ICCV'23
                            Doctoral Consortium</a>!</span></div>
                <div class="news-item hidden"><span class="news-date">[Jul 2023]</span><span class="news-text">Our
                        Paper, NeO 360, accepted to <a href="https://iccv2023.thecvf.com/">ICCV'23</a>! Grateful to have
                        trio of papers accepted to ECCV, CVPR and now ICCV</span></div>
                <div class="news-item hidden"><span class="news-date">[Jul 2023]</span><span class="news-text"><a
                            href="https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics">Awesome Implicit NeRF
                            Robotics</a> reached 800 stars on Github</span></div>
                <div class="news-item hidden"><span class="news-date">[Jul 2023]</span><span class="news-text">Reviewed
                        19 papers this year for <a href="https://nips.cc/">NeurIPS'23</a>, <a
                            href="https://cvpr2023.thecvf.com/">CVPR'23</a>, <a
                            href="https://iccv2023.thecvf.com/">ICCV'23</a> and <a
                            href="https://www.icra2023.org/">ICRA'23</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Jun 2023]</span><span class="news-text">Attended
                        <a href="https://cvpr2023.thecvf.com/">CVPR 2023</a> (Poster presentation of our paper,
                        CARTO)</span></div>
                <div class="news-item hidden"><span class="news-date">[Jun 2023]</span><span class="news-text">Gave
                        invited talks on <a
                            href="https://drive.google.com/file/d/1GYzThR8NZ6agZaeJbp010ZWcnTU9i5O7/view">Neural Fields
                            in Robotics</a> (Part 1 and 2) at <a href="#">3D Deep Learning Reading Group</a></span>
                </div>
                <div class="news-item hidden"><span class="news-date">[Apr 2023]</span><span class="news-text">Started
                        as a mentor at <a href="https://www.fatimafellowship.com/home">Fatima Fellowship</a>, supported
                        by <a href="https://huggingface.co/">Huggingface</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Feb 2023]</span><span class="news-text">Our
                        paper, <a href="http://carto.cs.uni-freiburg.de/">CARTO</a>, on articulated object
                        reconstruction accepted into <a href="https://cvpr2023.thecvf.com/">CVPR'23</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Oct 2022]</span><span class="news-text">Attended
                        <a href="https://eccv2022.ecva.net/">ECCV'22</a> virtually (Poster presentation of our paper, <a
                            href="https://zubair-irshad.github.io/projects/ShAPO.html">ShAPO</a>)</span></div>
                <div class="news-item hidden"><span class="news-date">[Aug 2022]</span><span class="news-text">Awarded
                        GRA Funding (with Dr. Zsolt Kira) from <a href="https://www.tri.global/">Toyota Research
                            Institute</a> for my PhD</span></div>
                <div class="news-item hidden"><span class="news-date">[Jul 2022]</span><span class="news-text">Our
                        paper, <a href="https://zubair-irshad.github.io/projects/ShAPO.html">ShAPO</a> on categorical
                        object reconstruction and 6D pose estimation, accepted into <a
                            href="https://eccv2022.ecva.net/">ECCV'22</a></span></div>
                <div class="news-item hidden"><span class="news-date">[May 2022]</span><span class="news-text">Our
                        paper, <a href="https://zubair-irshad.github.io/projects/SASRA.html">SASRA</a> on semantic
                        mapping for Vision-and-Language Navigation, accepted to <a
                            href="https://www.icpr2022.com/">ICPR'22</a></span></div>
                <div class="news-item hidden"><span class="news-date">[May 2022]</span><span class="news-text">Attended
                        <a href="https://www.icra2022.org/">ICRA'22</a> in person. Gave a talk on our paper, <a
                            href="https://github.com/zubair-irshad/CenterSnap">CenterSnap</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Jan 2022]</span><span class="news-text">Started
                        my second internship at <a href="https://www.tri.global/">Toyota Research Institute</a>, with
                        Machine Learning team in Bay Area, California</span></div>
                <div class="news-item hidden"><span class="news-date">[Jan 2022]</span><span class="news-text">Our
                        paper, <a href="https://zubair-irshad.github.io/projects/CenterSnap.html">CenterSnap</a> on
                        categorical 6D pose estimation, accepted to <a
                            href="https://www.icra2022.org/">ICRA'22</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Jul 2021]</span><span class="news-text">Started
                        my first internship at <a href="https://www.tri.global/">Toyota Research Institute</a>, with
                        Robotics perception team in Bay Area, California.</span></div>
                <div class="news-item hidden"><span class="news-date">[May 2021]</span><span class="news-text">Attended
                        <a
                            href="https://www.ieee-ras.org/about-ras/ras-calendar/upcoming-ras-events/event/1920-icra-2021">ICRA'21</a>
                        virtually. Gave a talk on our paper, <a
                            href="https://zubair-irshad.github.io/projects/robo-vln.html">Robo-VLN</a></span></div>
                <div class="news-item hidden"><span class="news-date">[Jan 2021]</span><span class="news-text">Our
                        paper, <a href="https://zubair-irshad.github.io/projects/robo-vln.html">Robo-VLN</a> on robotic
                        vision-and-language navigation, accepted to <a
                            href="https://www.ieee-ras.org/about-ras/ras-calendar/upcoming-ras-events/event/1920-icra-2021">ICRA
                            2021</a></span></div>
                <div class="news-item hidden"><span class="news-date">[May 2020]</span><span class="news-text">Started
                        as a Research Intern at <a href="https://www.sri.com/">SRI International</a> in Princeton, New
                        Jersey</span></div>
                <div class="news-item hidden"><span class="news-date">[Nov 2019]</span><span class="news-text">Started
                        my PhD at <a href="https://www.gatech.edu/">Georgia Tech</a> at the Robot Learning Lab with Dr.
                        Zsolt Kira</span></div>
                <div class="news-item hidden"><span class="news-date">[Aug 2019]</span><span class="news-text">Graduated
                        with Masters degree from <a href="https://www.gatech.edu/">Georgia Tech</a></span></div>
            </div>
            <div style="text-align: center;">
                <button class="show-more-btn" id="show-more-btn" onclick="toggleNews()">Show More</button>
            </div>
        </div>
    </section>

    <!-- Featured Publications Section -->
    <section class="publications-section" id="publications">
        <div class="container">
            <div class="publications-header">
                <h2>FEATURED PUBLICATIONS</h2>
                <span class="publications-intro">(For a complete list, please see my <a
                        href="https://scholar.google.com/citations?user=K2XA5XEAAAAJ&hl=en">Google Scholar
                        Profile</a>)</span>
            </div>

            <div class="publications-list">
                <!-- Publication 1: LBM -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/lbm_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation</h3>
                        <p class="authors">Jose Barreiros*, Andrew Beaulieu*, Aditya Bhat*, Rick Cory*, … <span
                                class="highlight">Muhammad Zubair Irshad</span>*, … Rares Ambrus, Kerri Fetzer-Borelli,
                            Ben Burchfiel, Hadas Kress-Gazit, Siyuan Feng, Stacie Ford, Russ Tedrake.</p>
                        <p class="venue"><strong>*Primary contributors (listed first, alphabetical)*</strong> | arXiv
                            2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2507.05331" class="btn">Paper</a>
                            <a href="https://toyotaresearchinstitute.github.io/lbm1/" class="btn">Project Page</a>
                            <a href="https://www.youtube.com/watch?v=DeLpnTgzJT4" class="btn">Video</a>
                            <a href="https://bostondynamics.com/blog/large-behavior-models-atlas-find-new-footing/"
                                class="btn">Blog (with BD)</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@article{lbmtri2025,
  title={A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation}, 
  author={TRI LBM Team and Jose Barreiros and Andrew Beaulieu and Aditya Bhat and Rick Cory and Eric Cousineau and Hongkai Dai and Ching-Hsin Fang and Kunimatsu Hashimoto and Muhammad Zubair Irshad and Masha Itkina and Naveen Kuppuswamy and Kuan-Hui Lee and Katherine Liu and Dale McConachie and Ian McMahon and Haruki Nishimura and Calder Phillips-Grafflin and Charles Richter and Paarth Shah and Krishnan Srinivasan and Blake Wulfe and Chen Xu and Mengchao Zhang and Alex Alspach and Maya Angeles and Kushal Arora and Vitor Campagnolo Guizilini and Alejandro Castro and Dian Chen and Ting-Sheng Chu and Sam Creasey and Sean Curtis and Richard Denitto and Emma Dixon and Eric Dusel and Matthew Ferreira and Aimee Goncalves and Grant Gould and Damrong Guoy and Swati Gupta and Xuchen Han and Kyle Hatch and Brendan Hathaway and Allison Henry and Hillel Hochsztein and Phoebe Horgan and Shun Iwase and Donovon Jackson and Siddharth Karamcheti and Sedrick Keh and Joseph Masterjohn and Jean Mercat and Patrick Miller and Paul Mitiguy and Tony Nguyen and Jeremy Nimmer and Yuki Noguchi and Reko Ong and Aykut Onol and Owen Pfannenstiehl and Richard Poyner and Leticia Priebe Mendes Rocha and Gordon Richardson and Christopher Rodriguez and Derick Seale and Michael Sherman and Mariah Smith-Jones and David Tago and Pavel Tokmakov and Matthew Tran and Basile Van Hoorick and Igor Vasiljevic and Sergey Zakharov and Mark Zolotas and Rares Ambrus and Kerri Fetzer-Borelli and Benjamin Burchfiel and Hadas Kress-Gazit and Siyuan Feng and Stacie Ford and Russ Tedrake},
  year={2025},
  eprint={2507.05331},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  url={https://arxiv.org/abs/2507.05331}, 
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 2: PolaRiS -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/polaris_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies</h3>
                        <p class="authors">Arhan Jain, Mingtong Zhang, Kanav Arora, William Chen, Marcel Torne, <span
                                class="highlight">Muhammad Zubair Irshad</span>, Sergey Zakharov, Yue Wang, Sergey
                            Levine, Chelsea Finn, Wei-Chiu Ma, Dhruv Shah, Abhishek Gupta, Karl Pertsch</p>
                        <p class="venue">arXiv 2026</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2512.16881" class="btn">Paper</a>
                            <a href="https://polaris-evals.github.io/" class="btn">Project Page</a>
                            <a href="https://github.com/arhanjain/PolaRiS/tree/main" class="btn">Code</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@misc{polaris,
        title   = {PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies},
        author  = {Jain, Arhan and Zhang, Mingtong and Arora, Kanav and Chen, William and Torne, Marcel and Irshad, Muhammad Zubair and Zakharov, Sergey and Wang, Yue and Levine, Sergey and Finn, Chelsea and Ma, Wei-Chiu and Shah, Dhruv and Gupta, Abhishek and Pertsch, Karl},
        year    = {2025}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 3: Posed-DROID -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/droid_teaser_final.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Posed-DROID: Scaling-Up Automatic Camera Calibration for DROID dataset</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Vitor Guizilini,
                            Alexander Khazatsky, Karl Pertsch</p>
                        <p class="venue">Part of DROID paper, published at Robotics: Science and System, RSS 2024</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2403.12945" class="btn">Paper</a>
                            <a href="http://medium.com/p/4ddfc45361d3" class="btn">Blog</a>
                            <a href="https://droid-dataset.github.io/" class="btn">Project Page</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@article{khazatsky2024droid,
    title   = {DROID: A Large-Scale In-The-Wild Robot Manipulation Dataset},
    author  = {Alexander Khazatsky and Karl Pertsch and Suraj Nair and ... and Muhammad Zubair Irshad and ... and Chelsea Finn},
    year    = {2024},
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 4: MVGD -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/mvgd_teaser_web.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion</h3>
                        <p class="authors">Vitor Guizilini, <span class="highlight">Muhammad Zubair Irshad</span>, Dian
                            Chen, Greg Shakhnarovich, Rares Ambrus</p>
                        <p class="venue">Computer Vision and Pattern Recognition, CVPR 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2501.18804" class="btn">Paper</a>
                            <a href="https://mvgd.github.io/" class="btn">Project Page</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@misc{guizilini2025zeroshotnovelviewdepth,
        title={Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion}, 
        author={Vitor Guizilini and Muhammad Zubair Irshad and Dian Chen and Greg Shakhnarovich and Rares Ambrus},
        year={2025},
        eprint={2501.18804},
        archivePrefix={arXiv},
        primaryClass={cs.CV}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 5: EmbodiedSplat -->
                <div class="publication-card">
                    <div class="publication-image">
                        <!-- <video autoplay loop muted playsinline>
                            <source src="images/publications/EmbodiedSplat_Architecture.png" type="video/mp4">
                        </video> -->
                        <img src="images/publications/EmbodiedSplat_Architecture.png" alt="Embodied Splat">
                    </div>
                    <div class="publication-content">
                        <h3>EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a
                            Mobile Device</h3>
                        <p class="authors">Gunjan Chhablani, Xiaomeng Ye, Rynaa Grover, <span class="highlight">Muhammad
                                Zubair Irshad</span>, Zsolt Kira</p>
                        <p class="venue">International Conference on Computer Vision, ICCV 2025 | Embodied AI Workshop,
                            CVPR 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2509.17430" class="btn">Paper</a>
                            <a href="https://gchhablani.github.io/embodied-splat/" class="btn">Project Page</a>
                            <a href="https://github.com/gchhablani/embodied-splat-v1" class="btn">Code</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 6: SplArt -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/splart_teaser_final.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting
                        </h3>
                        <p class="authors">Shengjie Lin, Jiading Fang, <span class="highlight">Muhammad Zubair
                                Irshad</span>, Vitor Campagnolo Guizilini, Rares Andrei Ambrus, Greg Shakhnarovich,
                            Matthew R. Walter</p>
                        <p class="venue">International Conference on Computer Vision, ICCV 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2506.03594" class="btn">Paper</a>
                            <a href="https://github.com/ripl/splart" class="btn">Code</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 7: Real2Render2Real -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/real2render2real_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Real2Render2Real: Scaling Robotic Manipulation Data Without Dynamics Simulation or Robot
                            Hardware</h3>
                        <p class="authors">Justin Yu, Letian Fu, Huang Huang, Karim El-Refai, Rares Andrei Ambrus,
                            Richard Cheng, <span class="highlight">Muhammad Zubair Irshad</span>, Ken Goldberg</p>
                        <p class="venue">Conference on Robot Learning, CORL 2025 (<strong>Oral Presentation</strong>)
                        </p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2505.09601" class="btn">Paper</a>
                            <a href="https://real2render2real.com/" class="btn">Project Page</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 8: ZeroGrasp -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/zero_grasp_teaser_final.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping</h3>
                        <p class="authors">Shun Iwase, <span class="highlight">Muhammad Zubair Irshad</span>, Katherine
                            Liu, Vitor Guizilini, Robert Lee, Takuya Ikeda, Amma Ayako, Koichi Nishiwaki, Kris Kitani,
                            Rares Ambrus, Sergey Zakharov</p>
                        <p class="venue">Computer Vision and Pattern Recognition, CVPR 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2504.10857" class="btn">Paper</a>
                            <a href="https://sh8.io/#/zerograsp" class="btn">Project Page</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@InProceedings{Iwase_CVPR_2025,
  author = {Iwase, Shun and, Irshad, Muhammad Zubair and Liu, Katherine and Guizilini, Vitor and Lee, Robert and Ikeda, Takuya and Amma, Ayako and Nishiwaki, Koichi and Kitani, Kris and Ambrus, Rares and Zakharov, Sergey},
  title = {ZeroGrasp: Zero-Shot Shape Reconstruction Enabled Robotic Grasping},
  booktitle = {CVPR},
  year = {2025}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 9: FastMap -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/fastmap_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>FastMap: Revisiting Dense and Scalable Structure from Motion</h3>
                        <p class="authors">Jiahao Li, Haochen Wang, <span class="highlight">Muhammad Zubair
                                Irshad</span>, Igor Vasiljevic, Matthew R. Walter, Vitor Campagnolo Guizilini, Greg
                            Shakhnarovich</p>
                        <p class="venue">International Conference on 3D Vision, 3DV 2026 (<strong>Oral
                                Presentation</strong>)</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2505.04612" class="btn">Paper</a>
                            <a href="https://jiahao.ai/fastmap/" class="btn">Project Page</a>
                            <a href="https://github.com/pals-ttic/fastmap" class="btn">Code</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 10: Neural Fields Survey -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="images/publications/robonerf_timeline_v2-768x246.png" alt="Neural Fields Survey">
                    </div>
                    <div class="publication-content">
                        <h3>Neural Fields in Robotics: A Survey</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Mauro Comi, Yen-Chen
                            Lin, Nick Heppert, Abhinav Valada, Zsolt Kira, Rares Ambrus, Johnathan Trembley</p>
                        <p class="venue">In Submission, 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2410.20220" class="btn">Paper</a>
                            <a href="https://robonerf.github.io/" class="btn">Project Page</a>
                            <a href="https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics" class="btn">Github
                                List</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@article{irshad2024neuralfieldsroboticssurvey,
  title={Neural Fields in Robotics: A Survey},
  author={Muhammad Zubair Irshad and Mauro Comi and Yen-Chen Lin and Nick Heppert and Abhinav Valada and Rares Ambrus and Zsolt Kira and Jonathan Tremblay},
  journal={arXiv preprint arXiv:2410.20220},
  year={2024}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 11: NeRF-MAE -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="videos/animation_nerf_mae_white-ezgif.com-resize.gif" alt="NeRF-MAE">
                    </div>
                    <div class="publication-content">
                        <h3>NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural
                            Radiance Fields</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Sergey Zakharov, Vitor
                            Guizilini, Adrien Gaidon, Zsolt Kira, Rares Ambrus</p>
                        <p class="venue">European Conference on Computer Vision, ECCV 2024</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2404.01300.pdf" class="btn">Paper</a>
                            <a href="https://nerf-mae.github.io/" class="btn">Project Page</a>
                            <a href="https://github.com/zubair-irshad/NeRF-MAE" class="btn">Code</a>
                            <a href="https://youtu.be/D60hlhmeuJI" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{irshad2024nerfmae,
    title={NeRF-MAE: Masked AutoEncoders for Self-Supervised 3D Representation Learning for Neural Radiance Fields},
    author={Muhammad Zubair Irshad and Sergey Zakharov and Vitor Guizilini and Adrien Gaidon and Zsolt Kira and Rares Ambrus},
    journal={European Conference on Computer Vision (ECCV)},
    year={2024}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 12: POGS -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/pogs_teaser_final.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>POGS: Persistent Object Gaussian Splat for Tracking Human and Robot Manipulation of
                            Irregularly Shaped Objects</h3>
                        <p class="authors">Justin Yu, Kush Hari, Karim El-Refai, Arnav Dalil, Justin Kerr, Chung-Min
                            Kim, Richard Cheng, <span class="highlight">Muhammad Zubair Irshad</span>, Ken Goldberg</p>
                        <p class="venue">International Conference on Robotics and Automation, ICRA 2025</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2503.05189" class="btn">Paper</a>
                            <a href="https://berkeleyautomation.github.io/POGS/" class="btn">Project Page</a>
                            <a href="https://github.com/uynitsuj/pogs" class="btn">Code</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 13: RoVi-Aug -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/rovi_aug_teaser_final.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>RoVi-Aug: Robot and Viewpoint Augmentation for Cross-Embodiment Robot Learning</h3>
                        <p class="authors">Lawrence Chen*, Chenfeng Xu*, Karthik Dharmarajan, <span
                                class="highlight">Muhammad Zubair Irshad</span>, Richard Cheng, Kurt Keutzer, Masayoshi
                            Tomizuka, Quan Vuong, Ken Goldberg</p>
                        <p class="venue">Conference on Robot Learning, CoRL 2024 (<strong>Oral Presentation</strong>,
                            Top 4.3%)</p>
                        <div class="publication-links">
                            <a href="https://www.arxiv.org/pdf/2409.03403" class="btn">Paper</a>
                            <a href="https://rovi-aug.github.io/" class="btn">Project Page</a>
                            <a href="https://github.com/BerkeleyAutomation/rovi-aug" class="btn">Code</a>
                            <a href="https://techxplore.com/news/2024-10-augmentation-algorithm-skills-robots.html"
                                class="btn">Press</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 14: LEGS -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/LEGS_demo.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Language-Embedded Gaussian Splats (LEGS): Incrementally Building Room-Scale Representations
                            with a Mobile Robot</h3>
                        <p class="authors">Justin Yu*, Kush Hari*, Kishore Srinivas*, Adam Rashid, Chung Min Kim, Justin
                            Kerr, Richard Cheng, <span class="highlight">Muhammad Zubair Irshad</span>, Ashwin
                            Balakrishna, Thomas Kollar, Ken Goldberg</p>
                        <p class="venue">International Conference on Intelligent Robots and System, IROS 2024</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2409.18108" class="btn">Paper</a>
                            <a href="https://berkeleyautomation.github.io/LEGS/" class="btn">Project Page</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 15: Open X-Embodiment -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/openx_embodiment_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Open X‑Embodiment: Robotic Learning Datasets and RT‑X Models</h3>
                        <p class="authors">Open X-Embodiment Collaboration, Abby O'Neill, Abdul Rehman, Abhinav Gupta, …
                            <span class="highlight">Muhammad Zubair Irshad</span> et al.
                        </p>
                        <p class="venue">IEEE International Conference on Robotics and Automation, ICRA 2024 (Best Paper
                            Award)</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2310.08864" class="btn">Paper</a>
                            <a href="https://robotics-transformer-x.github.io/" class="btn">Project Page</a>
                            <a href="https://github.com/google-deepmind/open_x_embodiment" class="btn">Code</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 16: ICE-G -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/icegaussians.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>ICE-G: Image Conditional Editing of 3D Gaussian Splats</h3>
                        <p class="authors">Vishnu Jaganathan, Hannah Huang, <span class="highlight">Muhammad Zubair
                                Irshad</span>, Varun Jampani, Amit Raj, Zsolt Kira</p>
                        <p class="venue">CVPR AI for Content Creation Workshop, 2024</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2406.08488" class="btn">Paper</a>
                            <a href="https://ice-gaussian.github.io/" class="btn">Project Page</a>
                            <a href="https://youtu.be/dDsCwRXixp8" class="btn">Video</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 17: PhD Thesis -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="images/publications/thesis_teaser-768x423.png" alt="PhD Thesis">
                    </div>
                    <div class="publication-content">
                        <h3>Learning 3D Robotics Perception using Inductive Priors</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span></p>
                        <p class="venue">PhD Thesis, Georgia Institute of Technology 2023</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2405.20364" class="btn">Paper</a>
                            <a href="https://youtu.be/3M2ze1gZjj8" class="btn">Video</a>
                            <a href="https://repository.gatech.edu/entities/publication/01ef518d-5235-4131-990c-f552d3b309c6"
                                class="btn">Thesis Link</a>
                        </div>
                    </div>
                </div>

                <!-- Publication 18: NeO 360 -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/neo_360_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Sergey Zakharov,
                            Katherine Liu, Vitor Guizilini, Thomas Kollar, Adrien Gaidon, Zsolt Kira, Rares Ambrus</p>
                        <p class="venue">International Conference on Computer Vision, ICCV 2023</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2308.12967.pdf" class="btn">Paper</a>
                            <a href="https://zubair-irshad.github.io/projects/neo360.html" class="btn">Project Page</a>
                            <a href="https://github.com/zubair-irshad/NeO-360" class="btn">Code</a>
                            <a href="https://youtu.be/avmylyL_V8c" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{irshad2023neo360,
  title={NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes},
  author={Muhammad Zubair Irshad and Sergey Zakharov and Katherine Liu and Vitor Guizilini and Thomas Kollar and Adrien Gaidon and Zsolt Kira and Rares Ambrus},
  journal={International Conference on Computer Vision (ICCV)},
  year={2023},
  url={https://arxiv.org/abs/2308.12967},
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 19: CARTO -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="images/publications/carto_teaser.png" alt="CARTO">
                    </div>
                    <div class="publication-content">
                        <h3>CARTO: Category and Join Agnositc Reconstruction of Articulated Objects</h3>
                        <p class="authors">Nick Heppert, <span class="highlight">Muhammad Zubair Irshad</span>, Sergey
                            Zakharov, Katherine Liu, Rares Ambrus, Jeannette Bohg, Abhinav Valada, Thomas Kollar</p>
                        <p class="venue">Computer Vision and Pattern Recognition, CVPR 2023</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2303.15782.pdf" class="btn">Paper</a>
                            <a href="http://carto.cs.uni-freiburg.de/" class="btn">Project Page</a>
                            <a href="https://github.com/robot-learning-freiburg/CARTO" class="btn">Code</a>
                            <a href="https://youtu.be/nqImGPO5pn0" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{heppert2023carto,
  title={Carto: Category and joint agnostic reconstruction of articulated objects},
  author={Heppert, Nick and Irshad, Muhammad Zubair and Zakharov, Sergey and Liu, Katherine and Ambrus, Rares Andrei and Bohg, Jeannette and Valada, Abhinav and Kollar, Thomas},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={21201--21210},
  year={2023}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 20: ShAPO -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/shapo_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>ShAPO: Implicit Representations for Multi-Object Shape, Appearance, and Pose Optimization
                        </h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>*, Sergey Zakharov*,
                            Rares Ambrus, Thomas Kollar, Zsolt Kira, Adrien Gaidon</p>
                        <p class="venue">European Conference on Computer Vision, ECCV 2022</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2207.13691.pdf" class="btn">Paper</a>
                            <a href="https://zubair-irshad.github.io/projects/ShAPO.html" class="btn">Project Page</a>
                            <a href="https://github.com/zubair-irshad/shapo" class="btn">Code</a>
                            <a href="https://youtu.be/LMg7NDcLDcA" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{irshad2022shapo,
  title = {ShAPO: Implicit Representations for Multi-Object Shape Appearance and Pose Optimization},
  author = {Muhammad Zubair Irshad and Sergey Zakharov and Rares Ambrus and Thomas Kollar and Zsolt Kira and Adrien Gaidon},
  journal = {European Conference on Computer Vision (ECCV)},
  year = {2022}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 21: CenterSnap -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/centersnap_pose.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>CenterSnap: Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and
                            Size Estimation</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Thomas Kollar, Michael
                            Laskey, Kevin Stone, Zsolt Kira</p>
                        <p class="venue">IEEE International Conference on Robotics and Automation, ICRA 2022</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2203.01929.pdf" class="btn">Paper</a>
                            <a href="https://zubair-irshad.github.io/projects/CenterSnap.html" class="btn">Project
                                Page</a>
                            <a href="https://github.com/zubair-irshad/CenterSnap" class="btn">Code</a>
                            <a href="https://www.youtube.com/watch?v=Bg5vi6DSMdM" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{irshad2022centersnap,
	title = {CenterSnap: Single-Shot Multi-Object 3D Shape Reconstruction and Categorical 6D Pose and Size Estimation},
	author = {Muhammad Zubair Irshad and Thomas Kollar and Michael Laskey and Kevin Stone and Zsolt Kira},
	journal = {IEEE International Conference on Robotics and Automation (ICRA)},
	year = {2022}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 22: RoboVLN -->
                <div class="publication-card">
                    <div class="publication-image">
                        <video autoplay loop muted playsinline>
                            <source src="videos/robovln_teaser.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="publication-content">
                        <h3>Hierarchical Cross-Modal Agent for Robotics Vision-and-Language Navigation</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Chih-Yao Ma, Zsolt
                            Kira</p>
                        <p class="venue">IEEE International Conference on Robotics and Automation, ICRA 2021</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2104.10674.pdf" class="btn">Paper</a>
                            <a href="https://zubair-irshad.github.io/projects/robo-vln.html" class="btn">Project
                                Page</a>
                            <a href="https://github.com/GT-RIPL/robo-vln" class="btn">Code</a>
                            <a href="https://youtu.be/y16x9n_zP_4" class="btn">Video</a>
                            <span class="btn btn-bibtex" onclick="toggleBibtex(this)">BibTeX</span>
                        </div>
                        <div class="bibtex-container">
                            <div class="bibtex-box">
                                <button class="bibtex-copy-btn" onclick="copyBibtex(this)">Copy</button>
                                <pre>@inproceedings{irshad2021hierarchical,
  title={Hierarchical Cross-Modal Agent for Robotics Vision-and-Language Navigation},
  author={Muhammad Zubair Irshad and Chih-Yao Ma and Zsolt Kira},
  booktitle={Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)},
  year={2021}
}</pre>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Publication 23: SASRA -->
                <div class="publication-card">
                    <div class="publication-image">
                        <img src="images/publications/sasra.png" alt="SASRA">
                    </div>
                    <div class="publication-content">
                        <h3>SASRA: Semantically-aware Spatio-Temporal Reasoning Agent for Vision-and-Language Navigation
                        </h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Niluthpol Mithun,
                            Zachary Seymour, Han-Pang Chiu, Supun Samarasekera, Rakesh Kumar</p>
                        <p class="venue">International Conference on Pattern Recognition, ICPR 2022</p>
                        <div class="publication-links">
                            <a href="https://arxiv.org/pdf/2108.11945.pdf" class="btn">Paper</a>
                            <a href="https://zubair-irshad.github.io/projects/SASRA.html" class="btn">Project Page</a>
                            <a href="https://youtu.be/DsziGtgaJC0" class="btn">Video</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Machine Learning Workshops Section -->
    <section class="workshops-section">
        <div class="container">
            <h2>MACHINE LEARNING WORKSHOPS</h2>
            <div class="workshops-list">
                <div class="workshop-card">
                    <div class="workshop-image">
                        <img src="images/workshops/robonerf_thumbnail.jpg" alt="RoboNerF Workshop">
                    </div>
                    <div class="workshop-content">
                        <h3>RoboNerF: 1st Workshop On Neural Fields In Robotics</h3>
                        <p class="authors"><span class="highlight">Muhammad Zubair Irshad</span>, Nick Heppert, Jonathan
                            Tremblay, Shreyas Kousik, Zsolt Kira, Abhinav Valada</p>
                        <p class="venue">IEEE International Conference on Robotics and Automation (ICRA), 2024</p>
                        <div class="publication-links">
                            <a href="https://robonerf.github.io/2024/" class="btn">Webpage/Program/Accepted Papers</a>
                        </div>
                    </div>
                </div>

                <div class="workshop-card">
                    <div class="workshop-image">
                        <img src="images/workshops/robo_3dvlms.png" alt="3D VLMs Workshop">
                    </div>
                    <div class="workshop-content">
                        <h3>3D Vision Language Models (VLMs) for Robotics Manipulation: Opportunities and Challenges
                        </h3>
                        <p class="authors">Jiafei Duan, <span class="highlight">Muhammad Zubair Irshad</span>, Ishika
                            Singh,
                            Vitor Guizlini, Rares Ambrus, Zsolt Kira</p>
                        <p class="venue">Computer Vision and Pattern Recognition (CVPR), 2025</p>
                        <div class="publication-links">
                            <a href="https://robo-3dvlms.github.io/" class="btn">Webpage/Program/Call of papers</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Machine Learning Software Section -->
    <section class="software-section">
        <div class="container">
            <h2>MACHINE LEARNING SOFTWARE & REPO</h2>
            <div class="software-list">
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/Awesome-Implicit-NeRF-Robotics" class="repo-name">Awesome
                        Implicit NeRF Robotics</a>
                    <span class="stars"><i class="fas fa-star"></i> 1.5k</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/CenterSnap" class="repo-name">CenterSnap: Single-Shot
                        Multi-Object 3D Shape Reconstruction</a>
                    <span class="stars"><i class="fas fa-star"></i> 310</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/NeO-360" class="repo-name">NeO 360: Neural Fields for
                        Sparse View Synthesis</a>
                    <span class="stars"><i class="fas fa-star"></i> 230</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/droid-dataset/droid_policy_learning" class="repo-name">DROID Policy
                        Learning and Evaluation</a>
                    <span class="stars"><i class="fas fa-star"></i> 200</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/shapo" class="repo-name">ShAPO: Multi-Object Shape,
                        Appearance and Pose Optimization</a>
                    <span class="stars"><i class="fas fa-star"></i> 190</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/NeRF-MAE" class="repo-name">NeRF-MAE: Masked AutoEncoders
                        for Neural Radiance Fields</a>
                    <span class="stars"><i class="fas fa-star"></i> 100</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/zubair-irshad/Awesome-Robotics-3D"
                        class="repo-name">Awesome-Robotics-3D</a>
                    <span class="stars"><i class="fas fa-star"></i> 700</span>
                </div>
                <div class="software-card">
                    <i class="fab fa-github"></i>
                    <a href="https://github.com/GT-RIPL/robo-vln" class="repo-name">RoboVLN: Hierarchical Cross-Modal
                        Agent for VLN</a>
                    <span class="stars"><i class="fas fa-star"></i> 60</span>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <p>&copy; 2026 Zubair Irshad. Please feel free to copy with attribution.</p>
        </div>
    </footer>

    <script>
        function toggleNews() {
            const hiddenItems = document.querySelectorAll('.news-item.hidden');
            const btn = document.getElementById('show-more-btn');

            hiddenItems.forEach(item => {
                item.classList.toggle('shown');
            });

            if (btn.textContent === 'Show More') {
                btn.textContent = 'Show Less';
            } else {
                btn.textContent = 'Show More';
            }
        }

        function toggleBibtex(button) {
            const container = button.closest('.publication-content').querySelector('.bibtex-container');
            button.classList.toggle('active');
            container.classList.toggle('open');
        }

        function copyBibtex(button) {
            const pre = button.parentElement.querySelector('pre');
            const text = pre.textContent;

            navigator.clipboard.writeText(text).then(() => {
                button.textContent = 'Copied!';
                button.classList.add('copied');
                setTimeout(() => {
                    button.textContent = 'Copy';
                    button.classList.remove('copied');
                }, 2000);
            }).catch(err => {
                console.error('Failed to copy:', err);
            });
        }
    </script>
</body>

</html>
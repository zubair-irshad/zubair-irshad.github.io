<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="FSD: Fast Self-Supervised Single RGB-D to Categorical 3D Objects">
  <meta name="keywords" content="3D Reconstruction, 6D Pose Estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FSD: Fast Self-Supervised Single RGB-D to Categorical 3D Objects</title>
  <!-- <link rel="icon" type="image/x-icon" href="resources/tophat.png"> -->

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-124ZVGLK0S"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-124ZVGLK0S');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Import the component -->
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://zubairirshad.com">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://zubair-irshad.github.io/projects/CenterSnap.html">
              CenterSnap
            </a>
            <a class="navbar-item" href="https://zubair-irshad.github.io/projects/ShAPO.html">
              ShaPO
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h3 class="title is-2 publication-title">FSD: Fast Self-Supervised Single RGB-D to Categorical 3D
              Objects
              </h1>
              <!-- <div class="column is-full_width">
                <h2 class="title is-4">arXiv</h2>
              </div> -->
              <div class="is-size-5 publication-authors">

                <span class="author-block">
                  <a href="https://mayank.lunayach.me/">Mayank Lunayach</a><sup>1</sup>,
                </span>
                <span class="author-block">
                  <a href="https://zakharos.github.io/">Sergey Zakharov</a><sup>2</sup>,</span>


                <span class="author-block">
                  <a href="https://dianch.github.io/">Dian Chen</a><sup>2</sup>,</span>

                <span class="author-block">
                  <a href="https://www.linkedin.com/in/rare%C8%99-ambru%C8%99-b04812125/">Rares
                    Ambrus</a><sup>2</sup>,</span>

                <span class="author-block">
                  <a href="https://faculty.cc.gatech.edu/~zk15/">Zsolt Kira</a><sup>1</sup>
                </span>
                <span class="author-block">
                  <a href="https://zubairirshad.com">Muhammad Zubair Irshad</a><sup>1</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Georgia Tech,</span>
                <span class="author-block"><sup>2</sup>Toyota Research Institute</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <span class="link-block">
                    <a href="https://arxiv.org/pdf/2207.13691.pdf"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2207.13691"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
                  <!-- <span class="link-block">
                    <a href="https://youtu.be/LMg7NDcLDcA" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-youtube"></i>
                      </span>
                      <span>Video</span>
                    </a>
                  </span> -->
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/zubair-irshad/shapo"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code (Coming Soon)</span>
                    </a>
                  </span>

                  <!-- Google Collab Link. -->
                  <!-- <span class="link-block">
                    <a href="https://colab.research.google.com/github/zubair-irshad/shapo/blob/master/notebook/explore_ShAPO.ipynb"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fi-xnsuxl-google-colab"></i>
                      </span>
                      <span>Colab Notebook</span>
                    </a>
                  </span> -->

                  <!-- Poster Link. -->
                  <!-- <span class="link-block">
                    <a href="resources/ShAPO_Poster_ECCV2022.pdf"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Poster</span>
                    </a>
                  </span> -->
                  <!-- Dataset Link. -->
                  <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
                </div>

              </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">

        <!-- <video id="method" autoplay muted loop height="100%">
          <source src="resources/ShAPO_teaser.mp4" type="video/mp4">
        </video> -->
        <img src="resources/fsd_teaser.jpg" alt="Image description" style="width: 100%; height: auto;">
        <!-- <img src="resources/fsd_teaser.jpg" class="interpolation-image" alt="Interpolate start reference image." /> -->
        <!-- <video id="teaser" autoplay muted loop height="100%">
        <source src="static/images/CS_Pose.mp4"
                type="video/mp4">
      </video> -->
        <!-- <h3 class="subtitle has-text-centered"> -->
        <div class="content has-text-centered">
          <p>
            We present <span class="dnerf">FSD:</span> a fast self-supervised categorical 6D pose and size estimation
            and
            shape reconstruction
            framework. Our method is a fully feed-forward approach that doesnâ€™t require any real-world 3D labels such as
            meshes or
            6D pose annotations and it does not necessitate inference time optimization.
          <p>
            <!-- </h3> -->
        </div>
      </div>
    </div>
    <!-- <h2 class="title is-3">Reconstruction Results</h2>
        <h3 class="title is-4">Multi-layer Shapes</h3>
    <div class="content has-text-justified">
      <p>
          Our method can reconstruct internal structures of various
          shapes.
      </p>
    </div> -->
    <!-- <div class="columns is-centered">
    <div class="column">
      <model-viewer alt="Neil Armstrong's Spacesuit from the Smithsonian Digitization Programs Office and National Air and Space Museum" src="static/predicted_mesh_1.glb" seamless-poster shadow-intensity="1" camera-controls enable-pan></model-viewer> -->

    <!-- <model-viewer bounds="tight" enable-pan="" src="./static/predicted_mesh_1.glb" ar="" ar-modes="webxr scene-viewer quick-look" camera-controls="" shadow-intensity="1" camera-orbit="-45deg 75deg auto" ar-status="not-presenting"> -->
    <!-- </model-viewer></div>
    <div class="column">
      <model-viewer bounds="tight" enable-pan="" src="./static/predicted_mesh_2.ply" ar="" ar-modes="webxr scene-viewer quick-look" camera-controls="" shadow-intensity="1" camera-orbit="-45deg 75deg auto" ar-status="not-presenting">
    </model-viewer></div>
    <div class="column">
      <model-viewer bounds="tight" enable-pan="" src="static/assets/multi-layer/2.glb" ar="" ar-modes="webxr scene-viewer quick-look" camera-controls="" shadow-intensity="1" camera-orbit="-45deg 75deg auto" ar-status="not-presenting">
    </model-viewer></div>
    <div class="column">
      <model-viewer bounds="tight" enable-pan="" src="static/assets/multi-layer/3.glb" ar="" ar-modes="webxr scene-viewer quick-look" camera-controls="" shadow-intensity="1" camera-orbit="-45deg 75deg auto" ar-status="not-presenting">
    </model-viewer></div>
    </div>
</section> -->
    <!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
    <section class="section">
      <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>

                In this work, we address the challenging task of
                3D object recognition without the reliance on real-world 3D
                labeled data. Our goal is to predict the 3D shape, size, and 6D
                pose of objects within a single RGB-D image, operating at the
                category level and eliminating the need for CAD models during
                inference.


              </p>
              <p>
                While existing self-supervised methods have made
                strides in this field, they often suffer from inefficiencies arising
                from non-end-to-end processing, reliance on separate models
                for different object categories, and slow surface extraction
                during the training of implicit reconstruction models; thus
                hindering both the speed and real-world applicability of the
                3D recognition process. Our proposed method leverages a
                multi-stage training pipeline, designed to efficiently transfer
                synthetic performance to the real-world domain. This approach
                is achieved through a combination of 2D and 3D supervised
                losses during the synthetic domain training, followed by the
                incorporation of 2D supervised and 3D self-supervised losses on
                real-world data in two additional learning stages.

              </p>
              <p>
                By adopting
                this comprehensive strategy, our method successfully overcomes
                the aforementioned limitations and outperforms existing self-
                supervised 6D pose and size estimation baselines on the NOCS
                test-set with a 16.4% absolute improvement in mAP for 6D
                pose estimation while running in near real-time at 5 Hz
              </p>
            </div>
          </div>
        </div>
        <!--/ Abstract. -->

        <!-- Method video. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Method</h2>
            <div class="content has-text-centered">
              <p>
                a) Forward pass of the proposed model across different training stages. From a single-view RGB-D
                observation, the model predicts a segmentation mask, depth map, object heatmap, pose map, and shape map.
                b) Batchified
                recursive point sampling is illustrated where the batch of concatenated 3D points and latent vectors are
                evaluated for SDF
                using a frozen shape auto-decoder. c) Losses for different training stages. Losses are color-coded based
                on the training stages
                and have solid out lines for real data and dotted lines for synthetic data.
              </p>
            </div>
            <!-- <video id="method" autoplay muted loop height="100%">
              <source src="resources/architecture720p.mp4" type="video/mp4">
            </video> -->
            <img src="resources/fsd_method.jpg" alt="Image description" style="width: 100%; height: auto;">

          </div>
        </div>
        <!--/ Method video. -->

        <!-- Qualitative Shape. -->
        <br>
        <!-- Paper video. -->
        <!-- <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Video</h2>
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/LMg7NDcLDcA?autoplay=1&mute=1" 
                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </div>
          </div>
        </div> -->
        <!--/ Paper video. -->

        <!-- Qualitative Optimizaiton all. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Qualitative 6D pose and size estimation comparison</h2>
            <div class="content has-text-centered">
              <p>
                Qualitative comparison: Our method vs. SSC-6D on NOCS Real275 test-set. Note that no real-world 3D
                labels were used for to train both methods. Our method is significantly more accurate and faster i.e.
                <b>runs in near real-time</b> at <b>5 Hz</b> per image.
              </p>
            </div>
            <img src="resources/fsd_qualitative2.jpg" alt="Image description" style="width: 65%; height: auto;">

            <video id="qualtiave" autoplay muted loop width="70%">
              <source src="resources/fsd_qualitative1.mp4" type="video/mp4">
            </video>
          </div>
        </div>


        <section class="section" id="BibTeX">
          <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <p>
              If you find our paper or pytorch code repository useful, please consider citing:
            </p>
            <pre><code>@inproceedings{lunayach2023fsd,
  title={FSD: Fast Self-Supervised Single RGB-D to Categorical 3D Objects},
  author={Mayank Lunayach and Sergey Zakharov and Dian Chen and Rares Ambrus and Zsolt Kira and Muhammad Zubair Irshad},
  journal={arXv},
  year={2023},
  url={https://arxiv.org/abs/2207.13691},
}</code></pre>
          </div>
        </section>


        <footer class="footer">
          <div class="container">
            <div class="content has-text-centered">
              <a class="icon-link" href="https://arxiv.org/pdf/2207.13691.pdf">
                <i class="fas fa-file-pdf"></i>
              </a>
              <a class="icon-link" href="https://github.com/zubair-irshad" class="external-link" disabled>
                <i class="fab fa-github"></i>
              </a>
            </div>
            <div class="columns is-centered">
              <div class="column is-8">
                <div class="content has-text-centered">
                  <p>Page template borrowed from <a href="https://github.com/nerfies/nerfies.github.io"><span
                        class="dnerf">Nerfies</span></a>.</p>
                </div>
              </div>
            </div>
          </div>
        </footer>

</body>

</html>